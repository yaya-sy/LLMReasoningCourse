{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPUSwGdaBcLCYSzFBlZXjf7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaya-sy/LLMReasoningCourse/blob/main/labs/lab2/lab2_corrected.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2: Improving the output quality of LLMs with repeated sampling"
      ],
      "metadata": {
        "id": "aDh211g8KHFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will see how to improve LLMs for French to English translation by scaling the translation candidates and using a reward score to pick the best translation."
      ],
      "metadata": {
        "id": "XzYXSkYNKSny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "id": "OmiLVEc9LUWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"haoranxu/X-ALMA-Preference\", split=\"train\")\n",
        "# get only 100 sentences for evaluation\n",
        "raw_datasets = raw_datasets.filter(lambda x: x[\"directions\"] == \"fr-en\")\n",
        "N = 100\n",
        "subset = raw_datasets.select(range(N))\n",
        "# use 'chosen' as gold English translations and 'source' as French sentences to translate to English"
      ],
      "metadata": {
        "id": "0MaSihwFa_Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(subset[0])"
      ],
      "metadata": {
        "id": "5MZ-HIPTFC_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use `HuggingFaceTB/SmolLM2-360M-Instruct` for this lab."
      ],
      "metadata": {
        "id": "hJ4kfHcSLZD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model and the tokenizer. Load the model on the GPU if available\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceTB/SmolLM2-360M-Instruct\", dtype=torch.bfloat16, token=\"\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-360M-Instruct\")\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Gr43GCRyLVkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Self-Confidence"
      ],
      "metadata": {
        "id": "qCZZvodaLbwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we will use self-confidence as reward."
      ],
      "metadata": {
        "id": "a8kanIC_NDDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu evaluate"
      ],
      "metadata": {
        "id": "SdSfiIIQMNUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "5omrIbfCMLrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "\n",
        "@torch.no_grad()\n",
        "def rollouts(corpus: List[str], batch_size: int=4, num_samples=4):\n",
        "    \"\"\"For each example in the batch, generate `num_samples` translations.\"\"\"\n",
        "    def tokenize(texts: List[str]):\n",
        "        \"\"\"Tokenize the texts\"\"\"\n",
        "        conversations = [\n",
        "            [{\"role\": \"user\",\n",
        "              \"content\": f\"You are given a French text, provide faithful translation to English.\\n\\n{text}\"}]\n",
        "            for text in texts]\n",
        "        # TODO: call apply_chat_template from the tokenizer class with the right arguments to output torch tensors of the token ids\n",
        "        # Which padding side to use? why?\n",
        "        templated = tokenizer.apply_chat_template(conversations, tokenize=False, add_generation_prompt=True)\n",
        "        tokenized = tokenizer(templated, padding_side=\"left\", padding=True, return_tensors=\"pt\")\n",
        "        return tokenized\n",
        "    data = sorted(enumerate(corpus), key=lambda x: tokenize([x[1]]).input_ids.shape[-1])\n",
        "\n",
        "    results = [None] * len(corpus)\n",
        "\n",
        "    for i in tqdm(range(0, len(data), batch_size)):\n",
        "        indices, texts = zip(*data[i : i + batch_size])\n",
        "\n",
        "        tokenized = tokenize(texts)\n",
        "        input_ids = tokenized.input_ids.to(model.device)\n",
        "        b, s = input_ids.shape\n",
        "        input_ids = input_ids.repeat_interleave(num_samples, dim=0)\n",
        "        attention_mask = tokenized.attention_mask.to(model.device)\n",
        "        attention_mask = attention_mask.repeat_interleave(num_samples, dim=0)\n",
        "\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            temperature=1.0,\n",
        "            top_p=0.4,\n",
        "            max_new_tokens=64,\n",
        "            do_sample=True\n",
        "        )\n",
        "        outputs = outputs.view(b, num_samples, -1)\n",
        "\n",
        "        for idx, predicted_ids in zip(indices, outputs):\n",
        "            generated_tokens = predicted_ids[:, s:]\n",
        "            translations = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "            results[idx] = translations\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "X8U4zh2VM2vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Likelihood self-confidence"
      ],
      "metadata": {
        "id": "l-t51w05fHEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Translate the French corpus with num_samples `[1, 2, 4, 8, 16]`\n",
        "2. Compute the log-likelihood of the translation using the LLM itsself\n",
        "3. Pick the most likely translation for each example\n",
        "4. Compute the bleu score, and observe the results"
      ],
      "metadata": {
        "id": "2I_dexJxeIxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "from typing import Tuple, List\n",
        "\n",
        "@torch.no_grad()\n",
        "def log_likelihood(texts: List[Tuple[str, str]], batch_size: int=16):\n",
        "    loglikelihoods = []\n",
        "\n",
        "    def tokenize(texts: List[Tuple[str, str]]):\n",
        "        conversations = [\n",
        "            [\n",
        "                {\"role\": \"user\",\n",
        "                \"content\": f\"You are given a French text, provide faithful translation to English.\\n\\nThe French text: {text}\"\n",
        "                },\n",
        "                {\"role\": \"assistant\",\n",
        "                \"content\": f\"{translation}\"\n",
        "                }\n",
        "            ]\n",
        "            for text, translation in texts\n",
        "        ]\n",
        "\n",
        "        templated = tokenizer.apply_chat_template(conversations, tokenize=False, add_generation_prompt=False)\n",
        "        tokenized = tokenizer(templated, padding_side=\"right\", padding=True, return_tensors=\"pt\")\n",
        "\n",
        "        # we need to find where the user message ends so we can ignore it for the prob computation. Remember we're only interested in p(translation|source)\n",
        "        prompts_only = [\n",
        "            tokenizer.apply_chat_template(\n",
        "                [conv[0]],\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "            for conv in conversations\n",
        "        ]\n",
        "        prompt_tokenized = tokenizer(prompts_only, padding_side=\"right\", padding=True, return_tensors=\"pt\")\n",
        "        prompt_lengths = (prompt_tokenized.input_ids != tokenizer.pad_token_id).sum(dim=1)\n",
        "\n",
        "        # Now mask the source sentence (user message), keep assistant response (translation)\n",
        "        labels = tokenized.input_ids.clone()\n",
        "        labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "        for i, prompt_len in enumerate(prompt_lengths):\n",
        "            labels[i, :prompt_len] = -100\n",
        "\n",
        "        tokenized[\"labels\"] = labels\n",
        "        return tokenized\n",
        "\n",
        "    for start in range(0, len(texts), batch_size):\n",
        "        batch = texts[start:start+batch_size]\n",
        "        tokenized = tokenize(batch).to(model.device)\n",
        "        labels = tokenized.labels[:, 1:].long().contiguous()\n",
        "        del tokenized[\"labels\"]\n",
        "        logits = model(**tokenized, output_hidden_states=True).logits\n",
        "        logits = logits[:, :-1, :].float()\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        b, s, *_ = log_probs.shape\n",
        "        nll_loss = F.nll_loss(\n",
        "            log_probs.view(-1, logits.shape[-1]),\n",
        "            labels.view(-1),\n",
        "            ignore_index=-100,\n",
        "            reduction=\"none\"\n",
        "        ).view(b, s)\n",
        "\n",
        "        valid_mask = (labels != -100).float()\n",
        "        per_sample_nll = (nll_loss * valid_mask).sum(dim=1) / valid_mask.sum(dim=1)\n",
        "        loglikelihoods.extend((-per_sample_nll).tolist())\n",
        "\n",
        "    return torch.tensor(loglikelihoods)"
      ],
      "metadata": {
        "id": "x8pQ9u6HMilw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loglikelihood_repeated_sampling(attempts=[1, 2, 4, 8, 16, 32, 64, 128]):\n",
        "    print(\"Rollouts...\")\n",
        "    results = {num_samples : rollouts(subset[\"source\"], num_samples=num_samples) for num_samples in attempts}\n",
        "    gold_and_candidates = {num_samples: [] for num_samples in attempts}\n",
        "    print(\"Loglikelihood self-confidence...\")\n",
        "    for num_samples in results:\n",
        "        for idx, candidates in tqdm(enumerate(results[num_samples]), total=N):\n",
        "            gold_translation = [subset[idx][\"chosen\"]] * len(candidates)\n",
        "            source = [subset[idx][\"source\"]] * len(candidates)\n",
        "            paired = list(zip(source, candidates))\n",
        "            loglikelihoods = log_likelihood(paired).cpu()\n",
        "            best_candidate_idx = loglikelihoods.argmax().item()\n",
        "            best_candidate = candidates[best_candidate_idx]\n",
        "            gold_and_candidates[num_samples].append((gold_translation[0], best_candidate, loglikelihoods[best_candidate_idx].item()))\n",
        "    return gold_and_candidates"
      ],
      "metadata": {
        "id": "a0i7fF6zMraL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_bleu(gold_and_candidates, self_confidence=\"logprob\"):\n",
        "    results = {}\n",
        "    for num_samples in gold_and_candidates:\n",
        "        references, candidates, logprobability = zip(*gold_and_candidates[num_samples])\n",
        "        results[num_samples] = {\"bleu\": metric.compute(predictions=candidates, references=references)[\"score\"],\n",
        "                                    self_confidence: sum(logprobability) / len(logprobability)}\n",
        "    return results"
      ],
      "metadata": {
        "id": "rebUAmSrYhau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "gold_and_candidates = loglikelihood_repeated_sampling()\n",
        "bleu_logprob = compute_bleu(gold_and_candidates)\n",
        "rows = []\n",
        "for n, metrics in bleu_logprob.items():\n",
        "    rows.append({'num_samples': n, 'metric': 'BLEU', 'value': metrics['bleu']})\n",
        "    rows.append({'num_samples': n, 'metric': 'Log Probability', 'value': metrics['logprob']})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Create facet plot\n",
        "g = sns.FacetGrid(df, col='metric', height=5, aspect=1.2, sharey=False)\n",
        "g.map_dataframe(sns.lineplot, x='num_samples', y='value', marker='o')\n",
        "g.set(xscale='log')\n",
        "\n",
        "# Set x-axis ticks\n",
        "for ax in g.axes.flat:\n",
        "    ax.set_xticks(list(bleu_logprob.keys()))\n",
        "    ax.set_xticklabels(list(bleu_logprob.keys()))\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "g.set_axis_labels('Number of Samples', 'Value')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TOjyJoG1_q_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entropy self-confidence"
      ],
      "metadata": {
        "id": "orZucyhTfMNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the function `log_likelihood` to compute the entropy. Repeat the previous experiment but with entropy."
      ],
      "metadata": {
        "id": "Yg3K-LOae7gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "from typing import Tuple, List\n",
        "\n",
        "@torch.no_grad()\n",
        "def entropy(texts: List[Tuple[str, str]], batch_size: int=16):\n",
        "    entropies = []\n",
        "\n",
        "    def tokenize_(texts: List[Tuple[str, str]]):\n",
        "        conversations = [\n",
        "            [\n",
        "                {\"role\": \"user\",\n",
        "                \"content\": f\"You are given a French text, provide faithful translation to English.\\n\\nThe French text: {text}\"\n",
        "                },\n",
        "                {\"role\": \"assistant\",\n",
        "                \"content\": f\"{translation}\"\n",
        "                }\n",
        "            ]\n",
        "            for text, translation in texts\n",
        "        ]\n",
        "\n",
        "        templated = tokenizer.apply_chat_template(conversations, tokenize=False, add_generation_prompt=False)\n",
        "        tokenized = tokenizer(templated, padding_side=\"right\", padding=True, return_tensors=\"pt\")\n",
        "\n",
        "        # we need to find where the user message ends so we can ignore it for the prob computation. Remember we're only interested in p(translation|source)\n",
        "        prompts_only = [\n",
        "            tokenizer.apply_chat_template(\n",
        "                [conv[0]],\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "            for conv in conversations\n",
        "        ]\n",
        "        prompt_tokenized = tokenizer(prompts_only, padding_side=\"right\", padding=True, return_tensors=\"pt\")\n",
        "        prompt_lengths = (prompt_tokenized.input_ids != tokenizer.pad_token_id).sum(dim=1)\n",
        "\n",
        "        # Now mask the source sentence (user message), keep assistant response (translation)\n",
        "        labels = tokenized.input_ids.clone()\n",
        "        labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "        for i, prompt_len in enumerate(prompt_lengths):\n",
        "            labels[i, :prompt_len] = -100\n",
        "\n",
        "        tokenized[\"labels\"] = labels\n",
        "        return tokenized\n",
        "\n",
        "    for start in range(0, len(texts), batch_size):\n",
        "        batch = texts[start:start+batch_size]\n",
        "        tokenized = tokenize_(batch).to(model.device)\n",
        "        labels = tokenized.labels[:, 1:].long().contiguous()\n",
        "        del tokenized[\"labels\"]\n",
        "        logits = model(**tokenized, output_hidden_states=True).logits\n",
        "        logits = logits[:, :-1, :].float()\n",
        "        probabilities = F.softmax(logits, dim=-1)\n",
        "        token_entropy = -torch.sum(probabilities * torch.log(probabilities), dim=-1)\n",
        "\n",
        "        valid_mask = (labels != -100).float()\n",
        "        per_sample_entropy = (token_entropy * valid_mask).sum(dim=1) / valid_mask.sum(dim=1)\n",
        "        entropies.extend(per_sample_entropy.tolist())\n",
        "\n",
        "    return torch.tensor(entropies)"
      ],
      "metadata": {
        "id": "3xWGUUlvYGYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy_repeated_sampling(attempts=[1, 2, 4, 8, 16, 32, 64, 128]):\n",
        "    print(\"Rollouts...\")\n",
        "    results = {num_samples : rollouts(subset[\"source\"], num_samples=num_samples) for num_samples in attempts}\n",
        "    gold_and_candidates = {num_samples: [] for num_samples in attempts}\n",
        "\n",
        "    print(\"Entropy self-confidence...\")\n",
        "    for num_samples in results:\n",
        "        for idx, candidates in tqdm(enumerate(results[num_samples]), total=N):\n",
        "            gold_translation = [subset[idx][\"chosen\"]] * len(candidates)\n",
        "            source = [subset[idx][\"source\"]] * len(candidates)\n",
        "            paired = list(zip(source, candidates))\n",
        "            entropies = entropy(paired).cpu()\n",
        "            best_candidate_idx = entropies.argmin().item()\n",
        "            best_candidate = candidates[best_candidate_idx]\n",
        "            gold_and_candidates[num_samples].append((gold_translation[0], best_candidate, entropies[best_candidate_idx].item()))\n",
        "    return gold_and_candidates"
      ],
      "metadata": {
        "id": "ZTzbLSvtZ9ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "gold_and_candidates = entropy_repeated_sampling()\n",
        "bleu_entropy = compute_bleu(gold_and_candidates, \"entropy\")\n",
        "\n",
        "rows = []\n",
        "for n, metrics in bleu_entropy.items():\n",
        "    rows.append({'num_samples': n, 'metric': 'BLEU', 'value': metrics['bleu']})\n",
        "    rows.append({'num_samples': n, 'metric': 'Entropy', 'value': metrics['entropy']})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Create facet plot\n",
        "g = sns.FacetGrid(df, col='metric', height=5, aspect=1.2, sharey=False)\n",
        "g.map_dataframe(sns.lineplot, x='num_samples', y='value', marker='o')\n",
        "g.set(xscale='log')\n",
        "\n",
        "# Set x-axis ticks\n",
        "for ax in g.axes.flat:\n",
        "    ax.set_xticks(list(bleu_entropy.keys()))\n",
        "    ax.set_xticklabels(list(bleu_entropy.keys()))\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "g.set_axis_labels('Number of Samples', 'Value')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xu4jtQn-auFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reward modeling"
      ],
      "metadata": {
        "id": "YJf83wgOfari"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train a reward model for translation quality scoring.\n",
        "\n",
        "## Data\n",
        "\n",
        "1. Get 1000 translation pairs from the dataset.\n",
        "2. Translate the French texts to English with repeated sampling (num_samples=4)\n",
        "3. Use the gold English texts as prefered translations and the translations of the model as rejected translations"
      ],
      "metadata": {
        "id": "cBnINYFsfzH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "We will use the Bradley-Terry model:\n",
        "\n",
        "$$\n",
        "p(y_c > y_r|x) = \\frac{\\exp(\\mathbf{c}_p \\cdot \\mathbf{w}^T)}{\\exp(\\mathbf{c}_p \\cdot \\mathbf{w}^T) + \\exp(\\mathbf{c}_r \\cdot \\mathbf{w}^T)}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $\\mathbf{c}_p = \\text{Transformer}(\\mathbf{x}, y_p)$\n",
        "- $\\mathbf{c}_r = \\text{Transformer}(\\mathbf{x}, y_r)$"
      ],
      "metadata": {
        "id": "JpydOpu5gf9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Derive the formula to get logistic regression model (see lecture2)\n",
        "2. Complete the class to implement a reward model\n",
        "3. Train the reward model"
      ],
      "metadata": {
        "id": "48Zgy08bhZGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from copy import deepcopy\n",
        "\n",
        "class RewardModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.transformer = deepcopy(model)\n",
        "        self.regression_head = nn.Linear(in_features=model.config.hidden_size, out_features=1)\n",
        "\n",
        "    def loss_fn(self, prefered_logits, rejected_logits):\n",
        "        loss = -(F.logsigmoid(prefered_logits.squeeze() - rejected_logits.squeeze())).mean()\n",
        "        return loss\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_layer_hidden_states = self.transformer(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True).hidden_states[-1]\n",
        "\n",
        "        mask_expanded = attention_mask.unsqueeze(-1).float()\n",
        "\n",
        "        masked_sum = (last_layer_hidden_states * mask_expanded).sum(dim=1).float()\n",
        "\n",
        "        seq_lengths = attention_mask.sum(dim=1, keepdim=True)  # [batch_size, 1]\n",
        "        averaged_hidden = masked_sum / seq_lengths\n",
        "\n",
        "        logits = self.regression_head(averaged_hidden)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "evBh93taQ2Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train(reward_model, prompts, prefered, rejected, lr=0.0001):\n",
        "    \"\"\" Training loop.\"\"\"\n",
        "    def tokenize_(texts: List[Tuple[str, str]]):\n",
        "        conversations = [\n",
        "            [\n",
        "                {\"role\": \"user\",\n",
        "                \"content\": f\"You are given a French text, provide faithful translation to English.\\n\\n{text}\"\n",
        "                },\n",
        "                {\"role\": \"assistant\",\n",
        "                \"content\": f\"{translation}\"\n",
        "                }\n",
        "            ]\n",
        "            for text, translation in texts\n",
        "        ]\n",
        "\n",
        "        templated = tokenizer.apply_chat_template(conversations, tokenize=False, add_generation_prompt=False)\n",
        "        tokenized = tokenizer(templated, padding_side=\"right\", padding=True, return_tensors=\"pt\")\n",
        "\n",
        "        return tokenized\n",
        "    batch_size = 2\n",
        "    optimizer = torch.optim.Adam(reward_model.parameters(), lr=lr)\n",
        "    reward_model.train()\n",
        "    prefered_data = list(zip(prompts, prefered))\n",
        "    rejected_data = list(zip(prompts, rejected))\n",
        "    for _ in range(2):\n",
        "        p_bar = tqdm(total=len(prefered_data))\n",
        "        for batch in range(0, len(prefered_data), batch_size):\n",
        "            p_bar.update(batch_size)\n",
        "            optimizer.zero_grad()\n",
        "            prefered_batch = prefered_data[batch:batch+batch_size]\n",
        "            rejected_batch = rejected_data[batch:batch+batch_size]\n",
        "            prefered_tokenized = tokenize_(prefered_batch).to(model.device)\n",
        "            rejected_tokenized = tokenize_(rejected_batch).to(model.device)\n",
        "\n",
        "            prefered_logits = reward_model(input_ids=prefered_tokenized[\"input_ids\"], attention_mask=prefered_tokenized[\"attention_mask\"])\n",
        "            rejected_logits = reward_model(input_ids=rejected_tokenized[\"input_ids\"], attention_mask=rejected_tokenized[\"attention_mask\"])\n",
        "            loss = reward_model.loss_fn(prefered_logits, rejected_logits)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(loss.item())\n",
        "    return reward_model"
      ],
      "metadata": {
        "id": "3r8CWPLuizdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset = raw_datasets.select(range(1000))\n",
        "prompts = train_subset[\"source\"]\n",
        "prefered = train_subset[\"chosen\"]\n",
        "rejected = rollouts(prompts)"
      ],
      "metadata": {
        "id": "0Gyc9QPDpuNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_repeated = []\n",
        "prefered_repeated = []\n",
        "rejected_repeated = []\n",
        "\n",
        "for prompt, pref, rej in zip(prompts, prefered, rejected):\n",
        "    prompts_repeated.extend([prompt] * len(rej))\n",
        "    prefered_repeated.extend([pref] * len(rej))\n",
        "    rejected_repeated.extend(rej)"
      ],
      "metadata": {
        "id": "g0PpTx3Q37ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompts_repeated[-1])\n",
        "print(prefered_repeated[-1])\n",
        "print(rejected_repeated[-1])"
      ],
      "metadata": {
        "id": "YfNnUU464n47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reward_model = RewardModel().to(model.device)"
      ],
      "metadata": {
        "id": "l8aM5_XDjLxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(reward_model, prompts_repeated, prefered_repeated, rejected_repeated)"
      ],
      "metadata": {
        "id": "gvHCu0vMpwx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use the reward model to select the translations."
      ],
      "metadata": {
        "id": "BSq1pg988tb0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ou9YFRLqhrd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}